{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc3f473-620e-4c6e-b0ab-5fb345ff7fed",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff5733; text-align:center; font-size:45px;\">🚀 Hello! I'm <b style=\"color:#33A1FF;\">Yahya Ahmad</b> 👋</h1>\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "I'm a beginner passionate about <b style=\"color:#FF914D;\">technology</b>, <b style=\"color:#FF914D;\">machine learning</b>, and <b style=\"color:#FF914D;\">Python programming</b>. \n",
    "I'm excited to learn and grow in the world of <b style=\"color:#33A1FF;\">data science</b> and <b style=\"color:#33A1FF;\">AI</b>. 🚀\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:30px;\">🎯 My Interests:</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li><b style=\"color:#FF914D;\">Programming</b>: Python </li>\n",
    "    <li><b style=\"color:#FF914D;\">Machine Learning</b>: Exploring PyTorch and TensorFlow</li>\n",
    "    <li><b style=\"color:#FF914D;\">Deep Learning AI</b>: Neural Networks & Computer Vision</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:30px;\">📬 Let's Connect!</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li>📧 <b>Email</b>: <a href=\"mailto:Ya0280780@gmail.com\" style=\"color:#FF914D;\">Ya0280780@gmail.com</a></li>\n",
    "    <li>🔗 <b>LinkedIn</b>: <a href=\"https://www.linkedin.com/in/yahya-ahmad-8538312b1/\" style=\"color:#FF914D;\">Yahya Ahmad on LinkedIn</a></li>\n",
    "    <li>💻 <b>GitHub</b>: <a href=\"https://github.com/Yahyaahmad09/Courses\" style=\"color:#FF914D;\">My GitHub Repository</a></li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1959a-99c7-49f3-8973-976b49fd09d6",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#E74C3C; text-align:center; font-size:45px;\">🔥 Introduction to PyTorch 🔥</h1>\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "<b>PyTorch</b> is a powerful, open-source deep learning framework that has become a popular choice for researchers and developers. \n",
    "It provides flexible tools for building and training neural networks, making it a key player in the field of \n",
    "<b style=\"color:#E74C3C;\">Artificial Intelligence (AI)</b> and <b style=\"color:#E74C3C;\">Machine Learning (ML)</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #3498db; font-size: 20px; text-align:center;\"><i>Whether you are a beginner or an experienced machine learning practitioner, PyTorch offers everything you need to build and experiment with models easily and efficiently.</i></p>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">✨ Key Features of PyTorch</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li><b style=\"color:#E67E22;\">Dynamic Computational Graphs</b>: PyTorch uses dynamic computation graphs, making it easy to change the model architecture during runtime.</li>\n",
    "    <li><b style=\"color:#E67E22;\">GPU Acceleration</b>: PyTorch supports GPU computation, speeding up the training process significantly for large models.</li>\n",
    "    <li><b style=\"color:#E67E22;\">Easy-to-Use API</b>: With a Pythonic API, PyTorch is simple to learn and integrate with other tools.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">🚀 Why Choose PyTorch?</h2>\n",
    "\n",
    "<p style=\"font-size:22px; color:#444;\">\n",
    "PyTorch's flexibility and ease of use make it an ideal framework for experimentation and development, especially for tasks like:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li>💡 <b style=\"color:#E67E22;\">Deep Learning</b>: Build and train neural networks from scratch.</li>\n",
    "    <li>🖼️ <b style=\"color:#E67E22;\">Computer Vision</b>: Leverage pre-trained models and work on image-related tasks.</li>\n",
    "    <li>📝 <b style=\"color:#E67E22;\">Natural Language Processing (NLP)</b>: Implement state-of-the-art language models and more.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"background-color: #f2f2f2; font-size: 18px; padding: 15px; border-radius: 8px; color:#444;\">\n",
    "<b>PyTorch has quickly gained popularity</b> due to its intuitive design and seamless integration with Python's scientific computing ecosystem.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">🛠️ Let's Get Started!</h2>\n",
    "\n",
    "<p style=\"font-size:22px; color:#444;\">\n",
    "In this notebook, we will cover the basics of PyTorch, including how to:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li>📌 Work with <b style=\"color:#E67E22;\">Tensors</b></li>\n",
    "    <li>📌 Build simple <b style=\"color:#E67E22;\">Neural Networks</b></li>\n",
    "    <li>📌 Train and evaluate <b style=\"color:#E67E22;\">Models</b></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align:center; font-size:24px; color:#E74C3C;\"><b>Let's dive in! 🚀</b></p>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3dc5b-86ff-46ef-92a1-fc3041bf0a59",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#3498db; text-align:center; font-size:45px;\">⚡ Importing PyTorch</h1>\n",
    "\n",
    "<p style=\"font-size:22px; color:#444; text-align:center;\">\n",
    "To begin working with PyTorch, you first need to import the <b style=\"color:#FF914D;\">torch</b> library into your Python environment.\n",
    "You can do this using the following code:\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #3498db; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">🔑 Code to Import PyTorch</h2>\n",
    "\n",
    "<p style=\"font-size:20px; background-color:#f2f2f2; padding:15px; border-radius:8px; color:#444;\">\n",
    "<b style=\"color:#E67E22;\">import torch</b>\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:20px; text-align:center; color:#444;\">\n",
    "Once the <b style=\"color:#FF914D;\">torch</b> library is imported, you can start using its features for deep learning tasks.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #3498db; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">🚀 Let's Get Started!</h2>\n",
    "\n",
    "<p style=\"font-size:22px; color:#444;\">\n",
    "Now that you've successfully imported PyTorch, you're ready to start experimenting with Tensors, neural networks, and more!\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:24px; color:#E74C3C;\"><b>Happy Coding! 🚀</b></p>\n",
    "\n",
    "<hr style=\"border:2px solid #3498db; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f7d3356b-8366-46b2-baa7-1c3a29309d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95584f60-6046-41ea-9b32-2b59c73b93f2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#E74C3C; text-align:center; font-size:40px;\">🔢 Tensors in PyTorch</h1>\n",
    "\n",
    "<p style=\"font-size:22px; color:#444; text-align:center;\">\n",
    "A <b style=\"color:#FF914D;\">tensor</b> is a multi-dimensional array, which is the core data structure in PyTorch. \n",
    "Tensors are similar to <b style=\"color:#FF914D;\">NumPy arrays</b>, but they can run on <b style=\"color:#3498db;\">GPU</b> for faster computation, making them essential for deep learning tasks.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">✨ Key Features of Tensors</h2>\n",
    "\n",
    "<ul style=\"font-size:22px; color:#444;\">\n",
    "    <li><b style=\"color:#E67E22;\">Multi-dimensional</b>: Tensors can be 0D (scalars), 1D (vectors), 2D (matrices), or higher-dimensional (like images or video frames).</li>\n",
    "    <li><b style=\"color:#E67E22;\">GPU Support</b>: Tensors can be moved to a <b style=\"color:#3498db;\">GPU</b> to accelerate computation, making them essential for training deep neural networks.</li>\n",
    "    <li><b style=\"color:#E67E22;\">Flexible Operations</b>: PyTorch allows for a wide range of operations on tensors, such as mathematical functions, element-wise operations, reshaping, slicing, and more.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:30px;\">🚀 Let's Create a Tensor</h2>\n",
    "\n",
    "<p style=\"font-size:22px; text-align:center; color:#444;\">\n",
    "Now that you know about tensors, let's create one and explore its properties.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #E74C3C; width:80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3838aa-4f53-46ff-8a6b-b07a144b9498",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#FF914D; text-align:center; font-size:35px;\">🚀 Creating Tensors with PyTorch</h1>\n",
    "\n",
    "<p style=\"font-size:12px; color:#444; text-align:center;\">\n",
    "In PyTorch, a <b style=\"color:#E67E22;\">tensor</b> is the fundamental data structure, similar to an array in NumPy but with additional capabilities like <b style=\"color:#3498db;\">GPU support</b>. PyTorch provides several ways to create tensors.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #FF914D; width:70%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:20px; text-align:center;\">✨ Ways to Create Tensors</h2>\n",
    "\n",
    "<ul style=\"font-size:18px; color:#444; list-style-position: inside;\">\n",
    "    <li><b style=\"color:#E67E22;\">From a List or NumPy Array</b>: You can create a tensor from a list or a NumPy array.</li>\n",
    "    <li><b style=\"color:#E67E22;\">With Random Values</b>: Use <b style=\"color:#3498db;\">torch.rand()</b> or <b style=\"color:#3498db;\">torch.randn()</b> for random values.</li>\n",
    "    <li><b style=\"color:#E67E22;\">With Zeros or Ones</b>: Use <b style=\"color:#3498db;\">torch.zeros()</b> or <b style=\"color:#3498db;\">torch.ones()</b>.</li>\n",
    "    <li><b style=\"color:#E67E22;\">From Existing Data</b>: Create tensors from images, text, or other data.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:2px solid #FF914D; width:70%;\">\n",
    "\n",
    "<h2 style=\"color:#3498db; font-size:24px; text-align:center;\">🧑‍💻 Let's Create a Simple Tensor</h2>\n",
    "\n",
    "<p style=\"font-size:18px; text-align:center; color:#444;\">\n",
    "Now, let's create a simple tensor and examine its properties!\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:2px solid #FF914D; width:70%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4522eb3e-101f-415d-b65a-956fea9f5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using empty\n",
    "a =  torch.empty(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564875ff-8499-4d9c-95dc-e7448632406f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e944724a-03b9-40c6-9d4c-93156f462645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Zeros\n",
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2f5403-7fc1-488b-84b7-f83fc26ec2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Ones\n",
    "torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472513e4-fb2a-44c3-86d4-ffdd36997be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using eye (identity matrics)\n",
    "torch.eye(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b861af35-768c-4a63-872c-790c2eecde72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4925, 0.9664, 0.5399, 0.0296],\n",
       "        [0.6162, 0.4501, 0.7501, 0.6083],\n",
       "        [0.8562, 0.9458, 0.0505, 0.0459]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using rand\n",
    "torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1404da4b-13e7-4346-83b7-f8e94737e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7713, 0.6872, 0.1526],\n",
       "        [0.8672, 0.1088, 0.2135],\n",
       "        [0.4261, 0.3654, 0.1990]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uing seed()\n",
    "torch.seed()\n",
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7875963a-ce96-4577-a2ae-fbcf34e6c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using tensor\n",
    "torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35815ba3-78c1-454e-a795-60e5390a4a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  5,  7,  9, 11, 13])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using arange\n",
    "torch.arange(3,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1291f66d-52ce-4fe7-a43f-82173e56cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  3.2857,  4.5714,  5.8571,  7.1429,  8.4286,  9.7143, 11.0000,\n",
       "        12.2857, 13.5714, 14.8571, 16.1429, 17.4286, 18.7143, 20.0000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using linespace\n",
    "torch.linspace(2,20,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9be8d288-0d20-404e-8f53-89f51efc1e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  using full\n",
    "torch.full((3,3),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf54c3-edad-4f6e-9acb-0a212d80b4b4",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 30px; color: #2c3e50; font-weight: bold;\">📏 Tensor Shape in PyTorch</h1>\n",
    "\n",
    "<p style=\"font-size: 18px; color: #34495e;\">\n",
    "  A <strong>tensor's shape</strong> defines its dimensions and the number of elements in each dimension. \n",
    "  Understanding tensor shapes is essential when working with deep learning models and mathematical operations in PyTorch.\n",
    "</p>\n",
    "\n",
    "<h3 style=\"font-size: 22px; color: #16a085;\">🔹 Checking the Shape of a Tensor</h3>\n",
    "\n",
    "<p style=\"font-size: 18px; color: #34495e;\">\n",
    "  You can check the shape of a tensor using the <code style=\"font-size: 18px; background-color: #ecf0f1; padding: 3px;\">.shape</code> or <code style=\"font-size: 18px; background-color: #ecf0f1; padding: 3px;\">.size()</code> attribute:\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"font-size: 18px; color: #34495e;\">\n",
    "  The <code>.shape</code> attribute returns the dimensions of the tensor, while <code>.size()</code> also gives the same result.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e8d8d96-3a47-4449-80de-d84170e275cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,15,20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3116e21d-dbf4-4022-a97d-78870299cfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 15, 20]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2948b8b2-4596-450a-8f3f-0301f66edbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b588f69-7f8c-4541-93c3-e82cdab7ed4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 15, 20]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reshaping use (reshape)\n",
    "y.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0b28731-044b-4b93-bd85-4c8d25c4e55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using zeros like\n",
    "torch.zeros_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "935adf8e-4440-4653-8614-591b275c6308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using ones like\n",
    "torch.ones_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b474548-5a3d-40bf-8902-eea5fc702a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0546, 0.2886, 0.3626],\n",
       "        [0.6403, 0.5733, 0.0200],\n",
       "        [0.7794, 0.9245, 0.7784],\n",
       "        [0.4173, 0.0116, 0.9541]], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using rand like \n",
    "torch.rand_like(y, dtype = float)   # but here it is essential to specify the data type otherwise it give error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b3c26-1cd7-462d-831a-fefcf0e3aa68",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 20px; color: #2980b9; font-weight: bold;\">🔢 Tensor Data Types in PyTorch</h1>\n",
    "\n",
    "<p style=\"font-size: 12px; color: #2c3e50;\">\n",
    "  In PyTorch, tensors support different <strong>data types</strong> to control precision, memory usage, and performance. \n",
    "  Choosing the right data type is important for speed optimization and numerical accuracy.\n",
    "</p>\n",
    "\n",
    "<h3 style=\"font-size: 15px; color: #1abc9c;\">🔹 Checking the Data Type of a Tensor</h3>\n",
    "\n",
    "<p style=\"font-size: 12px; color: #34495e;\">\n",
    "  You can check a tensor's data type using the <code style=\"font-size: 18px; padding: 3px;\">.dtype</code> attribute:\n",
    "</p>\n",
    "\n",
    "<pre style=\"font-size: 18px; color: #2c3e50; background-color: #ecf0f1; padding: 10px;\">\n",
    "\n",
    "<p style=\"font-size: 18px; color: #34495e;\">\n",
    "  The <code>.dtype</code> attribute gives you the data type of the tensor, which can be important for understanding precision \n",
    "  and ensuring your model is optimized correctly.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d1b34f3-0a4e-4a00-b176-dcac6014be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find data type\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8faaa681-efef-4544-9ffa-809375d3ab2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign data type   (when store in integer)\n",
    "torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fdbb342-0f8f-40c6-996b-1f8517904bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign data type  (when store in float)\n",
    "torch.tensor([[1,2,3],[4,5,6]],dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d1c5e29-cf5e-482c-a483-099f3da1d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 15., 20.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using to() (to convert into  float or integer)\n",
    "y.to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff912ae9-23f1-426c-bf19-1402ce243145",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff5733; text-align:center; font-size:35px;\">🧮 Mathematical Computations in PyTorch</h1>\n",
    "\n",
    "<hr style=\"border:2px solid #ff5733;\">\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">1️⃣ Basic Arithmetic Operations</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Addition</b> → <code>+</code>, <code>torch.add()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Subtraction</b> → <code>-</code>, <code>torch.sub()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Multiplication</b> → <code>*</code>, <code>torch.mul()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Division</b> → <code>/</code>, <code>torch.div()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">2️⃣ Advanced Mathematical Functions</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Exponentiation</b> → <code>torch.exp()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Square Root</b> → <code>torch.sqrt()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Logarithm</b> → <code>torch.log()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Power</b> → <code>torch.pow()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">3️⃣ Matrix Operations</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Matrix Addition</b> → <code>+</code>, <code>torch.add()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Matrix Multiplication</b> → <code>torch.matmul()</code>, <code>@</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Transpose</b> → <code>.T</code>, <code>torch.transpose()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Inverse</b> → <code>torch.inverse()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">4️⃣ Reduction Operations (Sum, Mean, Max, Min)</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Summation</b> → <code>torch.sum()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Mean/Average</b> → <code>torch.mean()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Maximum</b> → <code>torch.max()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Minimum</b> → <code>torch.min()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">5️⃣ Element-wise vs. Matrix-wise Computations</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Element-wise Operations</b></li>\n",
    "    <li><b style=\"color:#FF914D;\">Matrix-wise Operations</b></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">6️⃣ Broadcasting in PyTorch</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Automatic Expansion of Tensors</b></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">7️⃣ Special Functions</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Sine & Cosine</b> → <code>torch.sin()</code>, <code>torch.cos()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Hyperbolic Functions</b> → <code>torch.tanh()</code>, <code>torch.sinh()</code>, <code>torch.cosh()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Absolute Value</b> → <code>torch.abs()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">8️⃣ Comparison Operations</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Equal to</b> → <code>==</code>, <code>torch.eq()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Not Equal to</b> → <code>!=</code>, <code>torch.ne()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Greater than</b> → <code>></code>, <code>torch.gt()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Greater than or Equal to</b> → <code>>=</code>, <code>torch.ge()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Less than</b> → <code><</code>, <code>torch.lt()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Less than or Equal to</b> → <code><=</code>, <code>torch.le()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">9️⃣ In-Place Operations</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Addition (in-place)</b> → <code>torch.add_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Subtraction (in-place)</b> → <code>torch.sub_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Multiplication (in-place)</b> → <code>torch.mul_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Division (in-place)</b> → <code>torch.div_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Exponential (in-place)</b> → <code>torch.exp_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Square Root (in-place)</b> → <code>torch.sqrt_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Logarithm (in-place)</b> → <code>torch.log_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Power (in-place)</b> → <code>torch.pow_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Tanh (in-place)</b> → <code>torch.tanh_()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Absolute Value (in-place)</b> → <code>torch.abs_()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">🔟 Reshaping Tensors in PyTorch</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Reshaping a tensor</b> → <code>torch.view()</code>, <code>tensor.reshape()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Flattening a tensor</b> → <code>tensor.flatten()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Changing the dimensions</b> → <code>torch.unsqueeze()</code>, <code>torch.squeeze()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Permuting dimensions</b> → <code>torch.permute()</code></li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#33A1FF; font-size:25px;\">1️⃣1️⃣ NumPy and PyTorch</h2>\n",
    "<ul style=\"font-size:18px;\">\n",
    "    <li><b style=\"color:#FF914D;\">Conversion from NumPy to PyTorch tensor</b> → <code>torch.from_numpy()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">Conversion from PyTorch tensor to NumPy</b> → <code>tensor.numpy()</code></li>\n",
    "    <li><b style=\"color:#FF914D;\">NumPy-style operations in PyTorch</b> → PyTorch supports similar functions as NumPy for array manipulation and mathematical operations.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f077415-3527-4d8d-9461-881ad31d433b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Basic Arithmetic Operations</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c553865-4f4e-442f-b19c-c677c59a5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  Tensor\n",
    "t1  = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dec5bdc2-c2c1-481a-b593-44cde4c0a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6502, 0.4691, 0.6590],\n",
       "        [0.2622, 0.2572, 0.2135],\n",
       "        [0.8800, 0.2727, 0.8929]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a55a780-39a1-4686-abe4-235f4d2c38bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6502, 4.4691, 4.6590],\n",
       "        [4.2622, 4.2572, 4.2135],\n",
       "        [4.8800, 4.2727, 4.8929]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "t1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9a5fdb9-e251-433d-9efd-d8358fcedb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3498, -1.5309, -1.3410],\n",
       "        [-1.7378, -1.7428, -1.7865],\n",
       "        [-1.1200, -1.7273, -1.1071]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtaction\n",
    "t1 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2485f20b-e1cc-49a4-803b-9ad74ad976e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9506, 1.4074, 1.9770],\n",
       "        [0.7866, 0.7716, 0.6406],\n",
       "        [2.6401, 0.8182, 2.6787]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "t1 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71dc1b6c-5f8c-4fa7-a2fe-9389f27118d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3251, 0.2346, 0.3295],\n",
       "        [0.1311, 0.1286, 0.1068],\n",
       "        [0.4400, 0.1364, 0.4464]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Devision\n",
    "t1 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "134dd152-426f-477f-b084-60ed4b22c07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5487e-01, 1.7280e+00, 4.7496e-01],\n",
       "        [5.5489e-01, 4.3024e-01, 1.3385e+00],\n",
       "        [8.9836e-04, 8.1870e-01, 3.2217e-01]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modulos\n",
    "((t1 * 100)/4)%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72b2fff4-b959-4b95-abc8-eef48c19b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4228, 0.2201, 0.4343],\n",
       "        [0.0687, 0.0662, 0.0456],\n",
       "        [0.7745, 0.0744, 0.7972]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# power\n",
    "t1**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350afe5-257b-4bd0-9fd5-4ae948cc2d58",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Element wise oparation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb5ca-361a-42e2-997d-71282af0ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,2)\n",
    "b = torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3da01841-c404-426b-856f-557d6b8ca590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9974, 0.5021],\n",
      "        [0.5220, 0.1304]])\n",
      "tensor([[0.8244, 0.4092],\n",
      "        [0.8941, 0.2680]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbc0185b-ecef-4826-9c5e-14362defb1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8218, 0.9113],\n",
       "        [1.4161, 0.3984]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additon \n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d75ab26-547e-49aa-92aa-77f3f62bac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1731,  0.0929],\n",
       "        [-0.3721, -0.1375]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction \n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "566d8eb3-8a39-41c6-b8ee-8e8f620cfaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8222, 0.2055],\n",
       "        [0.4667, 0.0350]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication \n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66043705-cf1a-4094-aa5c-5236d48153d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8265, 0.8151],\n",
       "        [1.7129, 2.0542]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Devision \n",
    "b/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "420deefa-8779-4eee-b6a1-83dce0e68e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1731, 0.0929],\n",
       "        [0.5220, 0.1304]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modules\n",
    "a % b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77377adc-e4f6-474f-b747-90400421fbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8248, 0.6385],\n",
       "        [0.9432, 0.8422]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# power\n",
    "b**a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3941df2d-59e1-4218-a17f-90b6f3b0cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  2,  3, -4, -5])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([-1,2,3,-4,-5])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5d4347d-06e3-486d-b646-3a305343229c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absalute\n",
    "torch.abs(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68c0d3db-cfe7-4243-a413-73f510fca328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 2.1000, 3.8900, 8.9300, 5.5000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.tensor([3.5,2.1,3.89,8.93,5.5])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02335192-cf08-45a4-8aaa-3aabdeb66cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 2., 4., 9., 6.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round \n",
    "torch.round(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "913bbdfb-b57f-4585-8228-96e394ceb009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3., 4., 9., 6.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ceil\n",
    "torch.ceil(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2120d747-877b-4fcc-a138-d4fce9e29787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 3., 8., 5.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# floor\n",
    "torch.floor(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9326a084-9f71-4b71-b426-0d2fcf49fb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 2.1000, 3.8900, 4.0000, 4.0000])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clamp\n",
    "torch.clamp(t3, min=1, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bdcc8-58f8-4077-ada4-b8928587d8f0",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Reduction  Oparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c82eaf08-643f-41fc-9510-cb8fd11b8369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6., 1.],\n",
       "        [7., 4., 6.],\n",
       "        [7., 1., 3.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = torch.randint(size=(3,3), low=0, high=10, dtype=torch.float32)\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bbde1914-ff1f-4d65-ad34-62124d68fecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39.)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum()\n",
    "torch.sum(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96380a3a-87ce-422a-8657-97094a30aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18., 11., 10.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum along column\n",
    "torch.sum(t4, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f457ebd-0c0b-4b41-b9f9-24748951080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 17., 11.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum along rows\n",
    "torch.sum(t4, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "730bb7ca-14ef-42dd-b6cc-f89f833700b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3333)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean()\n",
    "torch.mean(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46972642-ae7d-489c-8e82-bf693533a78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0000, 3.6667, 3.3333])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean along column\n",
    "torch.mean(t4, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "856650c7-be96-482c-af4e-5f9a44b90f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median \n",
    "torch.median(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79bbbb94-f53f-4342-bea6-36f2ad48d339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max()\n",
    "torch.max(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fddb9995-c71f-4bb6-89e1-e6d189993835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84672.)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produc\n",
    "torch.prod(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08eb4af1-9e73-47c5-b442-2feb70b1e013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3452)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Daviation\n",
    "torch.std(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38472c0-b66c-431c-907f-45950f9a0cae",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Matrix Operations</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f369014-5494-463c-8b46-aa67e6a72c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.randint(size=(2,3), low=1, high=10)\n",
    "t6 = torch.randint(size=(3,2), low=1, high=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9bb323fd-9d79-47eb-a671-d00ae41e0cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 6, 5],\n",
      "        [6, 9, 9]])\n",
      "tensor([[7, 3],\n",
      "        [4, 3],\n",
      "        [8, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "86788c68-eff7-4d3b-91be-423160c8f966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 71,  51],\n",
       "        [150,  99]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matric Maltiplication\n",
    "torch.matmul(t5,t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65579b98-a18d-4447-9253-6c5ab87c8a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "v1  = torch.tensor([1,2,3])\n",
    "v2 = torch.tensor([4,5,6])\n",
    "print(v1)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0df4f19f-6320-4ab5-9a5a-3a208483a16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product\n",
    "torch.dot(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "079afa6a-6ff5-46b8-a83b-9b10c12aa7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 4, 8],\n",
       "        [3, 3, 6]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose \n",
    "torch.transpose(t6, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a032b8a7-8c6f-49da-90b7-a9e27257d188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 3., 8.],\n",
      "        [5., 1., 6.],\n",
      "        [7., 1., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(38.)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinat \n",
    "t7 = torch.randint(size=(3,3), low=1, high=10, dtype = torch.float32)\n",
    "print(t7)\n",
    "torch.det(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aa31e137-cfb0-42bd-9473-a2fffc3060a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0526, -0.1053,  0.2632],\n",
       "        [ 0.5789, -0.8421,  0.1053],\n",
       "        [-0.0526,  0.3947, -0.2368]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse\n",
    "torch.inverse(t7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d1526-35c4-42e8-b18a-efb5d838b65a",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Comparsion Oparation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2055e7b7-8396-4c66-8263-0ff79564f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 9],\n",
      "        [9, 6],\n",
      "        [3, 7]])\n",
      "tensor([[7, 1],\n",
      "        [4, 2],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.randint(size=(3,2), low=1, high=10)\n",
    "t9 = torch.randint(size=(3,2), low=1, high=10)\n",
    "print(t8)\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c04bc0fb-99c4-4838-88b1-2b7a1fc3f2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greater then\n",
    "t8 > t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d27b31f3-80a8-40f9-bbf4-3343b27f91bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [False, False],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less then and equal to \n",
    "t8 <= t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "228e05ee-7abb-476b-bf07-6dfdc9a730d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not equal to \n",
    "t9 != t8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a9688-6db0-4c60-b04a-36365fed408d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Special Functions</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "824477df-e252-409e-9353-63cfd384eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(size=(3,4), low=1, high=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "02f4c42b-17d9-4ecf-b851-81bc5d3e934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7918, 0.0000, 1.7918, 2.0794],\n",
       "        [1.7918, 0.6931, 1.9459, 1.0986],\n",
       "        [1.6094, 1.7918, 1.7918, 0.0000]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log\n",
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6ea49da0-1504-4187-89fb-db3e9084174b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4495, 1.0000, 2.4495, 2.8284],\n",
       "        [2.4495, 1.4142, 2.6458, 1.7321],\n",
       "        [2.2361, 2.4495, 2.4495, 1.0000]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square Root\n",
    "torch.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a42d2233-4383-4daf-ad84-3725b9196e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0343e+02, 2.7183e+00, 4.0343e+02, 2.9810e+03],\n",
       "        [4.0343e+02, 7.3891e+00, 1.0966e+03, 2.0086e+01],\n",
       "        [1.4841e+02, 4.0343e+02, 4.0343e+02, 2.7183e+00]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponantial \n",
    "torch.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b0a24420-864e-4860-938b-37af207dee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9975, 0.7311, 0.9975, 0.9997],\n",
       "        [0.9975, 0.8808, 0.9991, 0.9526],\n",
       "        [0.9933, 0.9975, 0.9975, 0.7311]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid\n",
    "torch.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2ec8e454-a0b9-4928-bf9e-4f5d73c81340",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randint(size=(3,4), low=1, high=10, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d6cea56c-805f-4b3e-a622-6eda7e560cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3422e-04, 9.9629e-01, 9.0850e-04, 2.4696e-03],\n",
       "        [9.5092e-01, 8.6713e-04, 4.7344e-02, 8.6713e-04],\n",
       "        [4.3317e-02, 4.3317e-02, 4.3317e-02, 8.7005e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax \n",
    "torch.softmax(b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c60e91b7-98c2-4641-8ebb-27909e14a512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 1, 6, 8],\n",
       "        [6, 2, 7, 3],\n",
       "        [5, 6, 6, 1]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relu \n",
    "torch.relu(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e3e9d-fa09-4060-b775-ade18b9dc1cb",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Inplace Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3e71a985-fe2e-4680-a800-481086148a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 6],\n",
       "        [1, 3, 1],\n",
       "        [5, 5, 8]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.randint(size=(3,3), low=1, high=10)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b512bbf-aaf9-443b-907e-17968e816e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 6],\n",
      "        [1, 3, 1],\n",
      "        [5, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "# to keep the changes permanetly, put underscore ( _ ) after the function\n",
    "c.relu_()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97922b4a-91e5-4bb5-877a-01b63431340e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Copying a Tensor</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df985ccd-1e14-4d1d-b733-2b643d3589d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 3],\n",
       "        [8, 1, 1]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.randint(size=(2,3), low=1, high=10)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3e2af6c9-1bf4-4ce2-9388-6136269719f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Assigment Oparator\n",
    "e = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4a43b266-0745-4814-a37f-21eeb9d71a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 3],\n",
       "        [8, 1, 1]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a74115bb-47c4-484c-b928-3e2603302b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 3],\n",
       "        [8, 1, 1]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d489fdf9-7253-4af3-a3fa-010c00f53e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[1][2] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d4e343f1-384f-46ac-b92a-f109e7732959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 3],\n",
       "        [8, 1, 4]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f37f3a33-6a3d-48d6-b088-31faf41e54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using of clone()\n",
    "e = d.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "64c3083c-77e5-4549-8216-4d2238e80d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 6, 3],\n",
      "        [8, 1, 4]])\n",
      "tensor([[9, 6, 3],\n",
      "        [8, 1, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(e)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7202c546-49b8-4330-9ac1-af67b41858b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2311815248640\n",
      "2311737397056\n"
     ]
    }
   ],
   "source": [
    "# both the tensor are same d and e to see\n",
    "print(id(d))\n",
    "print(id(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2d1e0f43-c910-4110-8296-b18c1cb4c42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406607e3-abfe-4ca7-81c7-83b14fef90f9",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Reshaping a Tensor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4a7e8778-bfbf-4d4d-af5f-ec5d84eba9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.ones(4,4)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b1a1723c-9abe-4233-aa97-b90532bf2915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[1., 1.],\n",
       "          [1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[1., 1.],\n",
       "          [1., 1.]]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "f.reshape(2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3efd3922-2b51-435e-84c4-27e3d683b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten \n",
    "f.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0dbcabb3-78d0-4650-b9b2-c76d07b399be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7895, 0.2164, 0.9363],\n",
      "         [0.8914, 0.3771, 0.6164]],\n",
      "\n",
      "        [[0.7408, 0.0844, 0.0827],\n",
      "         [0.0084, 0.7022, 0.0943]],\n",
      "\n",
      "        [[0.5728, 0.0439, 0.9115],\n",
      "         [0.9218, 0.0532, 0.9605]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  permute\n",
    "g = torch.rand(3,2,3)\n",
    "print(g)\n",
    "g.permute(2,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7405e87d-f94c-440b-851a-0989560f9053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 226, 226, 3])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsqueeze \n",
    "h = torch.rand(226,226,3)\n",
    "h.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "aebb101f-1baa-4fb2-8c81-748473c3a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.rand(1,3)\n",
    "k.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0dcae-77af-4fc7-bf70-f895c0c855dd",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#33A1FF; font-size:25px;\">Numpy Vs PyTorch</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6433be6b-5881-41a1-a4db-b74642cf096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch to Nmupy Array\n",
    "import numpy as np\n",
    "m = torch.tensor([1,2,3])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1c47a852-1290-4fef-b241-f703f0ef13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = m.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "48ae994f-2fe5-4036-9029-c86dc17653f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "08c4ada2-b3ca-44d6-86b2-f785c9bd2235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy to PyTorch \n",
    "p = np.array([1,2,3])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "15c3adcb-b181-42a0-855c-55f72dd66983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
